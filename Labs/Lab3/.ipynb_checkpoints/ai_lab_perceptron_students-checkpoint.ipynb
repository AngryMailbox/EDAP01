{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "retired-darkness",
   "metadata": {},
   "source": [
    "# Classification with the perceptron and logistic regression\n",
    "\n",
    "__Individual assignment__\n",
    "\n",
    "Author of the assignment: Pierre Nugues\n",
    "\n",
    "__Student name__: Måns Alklint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-expense",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "The objectives of this second assignment are to:\n",
    "\n",
    "1.  Write a linear regression program using gradient descent;\n",
    "2.  Write linear classifiers using the perceptron algorithm and logistic regression;\n",
    "3.  Experiment variations of the algorithms;\n",
    "4.  Evaluate your classifiers;\n",
    "5.  Experiment with popular tools;\n",
    "6.  Read a scientific article on optimization techniques and comment it;\n",
    "7.  Present your code, results, and comments in a short dissertation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-booking",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The gradient descent is a basic technique to estimate the parameters of cost functions. \n",
    "1. You will first use the gradient descent method to implement linear regression. \n",
    "2. You will then program the perceptron algorithm. \n",
    "3. Finally, you will improve the threshold function with the logistic curve (logistic regression). \n",
    "\n",
    "You will try various configurations and study their influence on the learning speed and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-salad",
   "metadata": {},
   "source": [
    "##  Programming language\n",
    "As programming language, you will use Python and write your code in this notebook.\n",
    "\n",
    "You need to have a comprehensive Python distribution such as Anaconda (https://www.anaconda.com/products/individual). This distribution is available on the student computers at the computer science department.\n",
    "Finally, you start a notebook by typing:\n",
    "\n",
    "`jupyter lab`\n",
    "\n",
    "in a terminal window and you select the notebook by clicking on it in the left pane.\n",
    "You run the pieces of code by typing shift+enter. You can also use a programming tool like VS Code or PyCharm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-bedroom",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Imports you may use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-stanford",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "You will implement the gradient descent method as explained in pages 694-697 in Russell-Norvig (pp. 719--720 in the 3rd ed.) and in the slides to compute regression lines. You will implement the stochastic and batch versions of the algorithm.\n",
    "\n",
    "You must try to do it yourself first. If you encounter difficulties, you also have the solution to this exercise in the section _Solution to linear regression_ below. See: https://github.com/pnugues/edap01/tree/master/gradient_descent_practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-privacy",
   "metadata": {},
   "source": [
    "### Your implementation of linear regression\n",
    "You will implement a regression program to predict the counts of _A_'s in a text from the total count of letters. You will apply it on two data sets corresponding to letter counts in the 15 chapters of the French and English versions of _Salammbô_, where the first column is the total count of characters and the second one, the count of A's. \n",
    "\n",
    "Start with either French or English and when your program ready, test it on the other language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_fr = np.array([[36961, 2503],\n",
    "                    [43621, 2992],\n",
    "                    [15694, 1042],\n",
    "                    [36231, 2487],\n",
    "                    [29945, 2014],\n",
    "                    [40588, 2805],\n",
    "                    [75255, 5062],\n",
    "                    [37709, 2643],\n",
    "                    [30899, 2126],\n",
    "                    [25486, 1784],\n",
    "                    [37497, 2641],\n",
    "                    [40398, 2766],\n",
    "                    [74105, 5047],\n",
    "                    [76725, 5312],\n",
    "                    [18317, 1215]])\n",
    "\n",
    "stat_en = np.array([[35680, 2217],\n",
    "                    [42514, 2761],\n",
    "                    [15162, 990],\n",
    "                    [35298, 2274],\n",
    "                    [29800, 1865],\n",
    "                    [40255, 2606],\n",
    "                    [74532, 4805],\n",
    "                    [37464, 2396],\n",
    "                    [31030, 1993],\n",
    "                    [24843, 1627],\n",
    "                    [36172, 2375],\n",
    "                    [39552, 2560],\n",
    "                    [72545, 4597],\n",
    "                    [75352, 4871],\n",
    "                    [18031, 1119]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-albania",
   "metadata": {},
   "source": [
    "From the datasets above, tell what is ${X}$ and $\\mathbf{y}$. Extract:\n",
    "1. The ${X}$ matrix, where you will have a column to model the intercept;\n",
    "2. The $\\mathbf{y}$ vector\n",
    "\n",
    "from these arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "stat_fr = np.array([[36961, 2503],\n",
    "                    [43621, 2992],\n",
    "                    [15694, 1042],\n",
    "                    [36231, 2487],\n",
    "                    [29945, 2014],\n",
    "                    [40588, 2805],\n",
    "                    [75255, 5062],\n",
    "                    [37709, 2643],\n",
    "                    [30899, 2126],\n",
    "                    [25486, 1784],\n",
    "                    [37497, 2641],\n",
    "                    [40398, 2766],\n",
    "                    [74105, 5047],\n",
    "                    [76725, 5312],\n",
    "                    [18317, 1215]])\n",
    "\n",
    "stat_en = np.array([[35680, 2217],\n",
    "                    [42514, 2761],\n",
    "                    [15162, 990],\n",
    "                    [35298, 2274],\n",
    "                    [29800, 1865],\n",
    "                    [40255, 2606],\n",
    "                    [74532, 4805],\n",
    "                    [37464, 2396],\n",
    "                    [31030, 1993],\n",
    "                    [24843, 1627],\n",
    "                    [36172, 2375],\n",
    "                    [39552, 2560],\n",
    "                    [72545, 4597],\n",
    "                    [75352, 4871],\n",
    "                    [18031, 1119]])\n",
    "\n",
    "x_fr = np.c_[np.ones(stat_fr.shape[0]), stat_fr[:, 0]]\n",
    "y_fr = stat_fr[:, 1]\n",
    "\n",
    "x_en = np.c_[np.ones(stat_en.shape[0]), stat_en[:, 0]]\n",
    "y_en = stat_en[:, 1]\n",
    "\n",
    "\n",
    "print(x_fr)\n",
    "print(y_fr)\n",
    "print(x_en)\n",
    "print(y_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-facing",
   "metadata": {},
   "source": [
    "Scale the arrays so that they fit in the range [0, 1] on the $x$ and $y$ axes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regression as reg\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "stat_fr = np.array([[36961, 2503],\n",
    "                    [43621, 2992],\n",
    "                    [15694, 1042],\n",
    "                    [36231, 2487],\n",
    "                    [29945, 2014],\n",
    "                    [40588, 2805],\n",
    "                    [75255, 5062],\n",
    "                    [37709, 2643],\n",
    "                    [30899, 2126],\n",
    "                    [25486, 1784],\n",
    "                    [37497, 2641],\n",
    "                    [40398, 2766],\n",
    "                    [74105, 5047],\n",
    "                    [76725, 5312],\n",
    "                    [18317, 1215]])\n",
    "\n",
    "stat_en = np.array([[35680, 2217],\n",
    "                    [42514, 2761],\n",
    "                    [15162, 990],\n",
    "                    [35298, 2274],\n",
    "                    [29800, 1865],\n",
    "                    [40255, 2606],\n",
    "                    [74532, 4805],\n",
    "                    [37464, 2396],\n",
    "                    [31030, 1993],\n",
    "                    [24843, 1627],\n",
    "                    [36172, 2375],\n",
    "                    [39552, 2560],\n",
    "                    [72545, 4597],\n",
    "                    [75352, 4871],\n",
    "                    [18031, 1119]])\n",
    "\n",
    "\n",
    "x_fr = np.c_[np.ones(stat_fr.shape[0]), stat_fr[:, 0]]\n",
    "y_fr = stat_fr[:, 1]\n",
    "\n",
    "x_en = np.c_[np.ones(stat_en.shape[0]), stat_en[:, 0]]\n",
    "y_en = stat_en[:, 1]\n",
    "\n",
    "x_fr= reg.normal(x_fr)\n",
    "y_fr= reg.normal(y_fr)\n",
    "x_en= reg.normal(x_en)\n",
    "y_en= reg.normal(y_en)\n",
    "\n",
    "print(x_fr)\n",
    "print(y_fr)\n",
    "print(x_en)\n",
    "print(y_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-valve",
   "metadata": {},
   "source": [
    "#### Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-anaheim",
   "metadata": {},
   "source": [
    "Implement the descent functions. You will pass `X`, `y`, the learning rate in the $\\alpha$ variable, the initial weight vector in `w`, the tolerance in the $\\epsilon$ variable, the maximal number of epochs in `epochs`. You will return `w`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-shopper",
   "metadata": {},
   "source": [
    "Batch descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-thickness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def fit_batch(X, y, alpha, w, epochs=500, epsilon=1.0e-5):\n",
    "    n_samples, n_features = X.shape\n",
    "    cost_history = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        y_pred = np.dot(X, w)\n",
    "        error = y_pred - y\n",
    "        cost = np.sum(error ** 2) / (2 * n_samples)\n",
    "        cost_history.append(cost)\n",
    "\n",
    "        if epoch > 0 and abs(cost_history[-1] - cost_history[-2]) < epsilon:\n",
    "            break\n",
    "\n",
    "        gradient = np.dot(X.T, error) / n_samples\n",
    "        w -= alpha * gradient\n",
    "\n",
    "    return w, cost_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-tobacco",
   "metadata": {},
   "source": [
    "Stochastic descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-surrey",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Write your code here\n",
    "def fit_stoch(X, y, alpha, w,\n",
    "              epochs=500,\n",
    "              epsilon=1.0e-5):\n",
    "    \"\"\"\n",
    "    Stochastic gradient descent\n",
    "    :param X:\n",
    "    :param y:\n",
    "    :param alpha:\n",
    "    :param w:\n",
    "    :param epochs:\n",
    "    :param epsilon:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global logs, logs_stoch\n",
    "    logs = []\n",
    "    logs_stoch = []\n",
    "    random.seed(0)\n",
    "    idx = list(range(len(X)))\n",
    "    for epoch in range(epochs):\n",
    "        random.shuffle(idx)\n",
    "        for i in idx:\n",
    "            y_hat = predict([X[i]], w)[0]\n",
    "            loss = y[i] - y_hat\n",
    "            gradient = vector.mul(loss, X[i])\n",
    "            w = vector.add(w, vector.mul(alpha, gradient))\n",
    "            logs_stoch += (w, alpha, sse(X, y, w))\n",
    "        if vector.norm(gradient) < epsilon:\n",
    "            print('Gradient', vector.norm(gradient))\n",
    "            break\n",
    "        logs += (w, alpha, sse(X, y, w))\n",
    "    print(\"Epoch\", epoch)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-upset",
   "metadata": {},
   "source": [
    "#### Applying batch descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-given",
   "metadata": {},
   "source": [
    "Apply the batch descent and print the final weight values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-asbestos",
   "metadata": {},
   "source": [
    "Visualize the points of your dataset as well as the regression lines you obtain using matplotlib or another similar program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-relations",
   "metadata": {},
   "source": [
    "#### Stochastic descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-concentration",
   "metadata": {},
   "source": [
    "Visualize the points of your dataset as well as the regression lines you obtain using matplotlib or another similar program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-least",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-collapse",
   "metadata": {},
   "source": [
    "### A solution to linear regression\n",
    "\n",
    "To help you start this assignment, your instructor wrote two Python notebooks that solve this exercise on linear regression. You can find them here: https://github.com/pnugues/edap01/tree/master/gradient_descent_practice\n",
    "\n",
    "2. The first notebook, `gradient_descent_numpy.ipynb`, uses Numpy. It is more compact, but you need to know a bit of numpy, for instance you multiply matrix `M` by matrix `N` with the operation `M @ N`\n",
    "1. The second notebook, `gradient_descent.ipynb`, only uses Python. The vector and matrix operations such as the dot product that are in the `vector.py` file. You can see how your instructor write the dot product or matrix multiplication operations so that there is no magic as with NumPy\n",
    "\n",
    "\n",
    "To run these programs, download them on your computer as well as the other program in the import list: vector.py\n",
    "\n",
    "The programs are also available as Python programs from\n",
    "https://github.com/pnugues/ilppp/tree/master/programs/ch04/python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-register",
   "metadata": {},
   "source": [
    "## Classification\n",
    "You will use the same data set as for linear regression, but this time to classify a chapter as French or English. Given a pair of numbers corresponding the letter count and count of _A_, you will predict the language:\n",
    "1. $\\mathbf{x} = (35680, 2217)$ $\\to$ $y$ = English\n",
    "2. $\\mathbf{x} = (37497, 2641)$ $\\to$ $y$ = French"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-belgium",
   "metadata": {},
   "source": [
    "### The dataset\n",
    "You will use the arrays below:\n",
    "1. `X` contains the counts of letters and of _A_ s as well as a column of ones for the intercept;\n",
    "2. `y` contains the classes, where 0 is for English and 1 for French."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1.0, 35680.0, 2217.0],\n",
    "              [1.0, 42514.0, 2761.0],\n",
    "              [1.0, 15162.0, 990.0],\n",
    "              [1.0, 35298.0, 2274.0],\n",
    "              [1.0, 29800.0, 1865.0],\n",
    "              [1.0, 40255.0, 2606.0],\n",
    "              [1.0, 74532.0, 4805.0],\n",
    "              [1.0, 37464.0, 2396.0],\n",
    "              [1.0, 31030.0, 1993.0],\n",
    "              [1.0, 24843.0, 1627.0],\n",
    "              [1.0, 36172.0, 2375.0],\n",
    "              [1.0, 39552.0, 2560.0],\n",
    "              [1.0, 72545.0, 4597.0],\n",
    "              [1.0, 75352.0, 4871.0],\n",
    "              [1.0, 18031.0, 1119.0],\n",
    "              [1.0, 36961.0, 2503.0],\n",
    "              [1.0, 43621.0, 2992.0],\n",
    "              [1.0, 15694.0, 1042.0],\n",
    "              [1.0, 36231.0, 2487.0],\n",
    "              [1.0, 29945.0, 2014.0],\n",
    "              [1.0, 40588.0, 2805.0],\n",
    "              [1.0, 75255.0, 5062.0],\n",
    "              [1.0, 37709.0, 2643.0],\n",
    "              [1.0, 30899.0, 2126.0],\n",
    "              [1.0, 25486.0, 1784.0],\n",
    "              [1.0, 37497.0, 2641.0],\n",
    "              [1.0, 40398.0, 2766.0],\n",
    "              [1.0, 74105.0, 5047.0],\n",
    "              [1.0, 76725.0, 5312.0],\n",
    "              [1.0, 18317.0, 1215.0]])\n",
    "y = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "              1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-package",
   "metadata": {},
   "source": [
    "We visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fr = [x[1] for i, x in enumerate(X) if y[i] == 1]\n",
    "y_fr = [x[2] for i, x in enumerate(X) if y[i] == 1]\n",
    "x_en = [x[1] for i, x in enumerate(X) if y[i] == 0]\n",
    "y_en = [x[2] for i, x in enumerate(X) if y[i] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_fr, y_fr, color='red')\n",
    "plt.scatter(x_en, y_en, color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-chair",
   "metadata": {},
   "source": [
    "### Normalize the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-engagement",
   "metadata": {},
   "source": [
    "Gradient descent algorithms can be very sensitive to the range. Therefore, we normalize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(Xy):\n",
    "    maxima = np.amax(Xy, axis=0)\n",
    "    Xy = 1/maxima * Xy\n",
    "    return (Xy, maxima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm, maxima = normalize(X)\n",
    "X_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-stewart",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Perceptron\n",
    "\n",
    "1. Write the perceptron program as explained in pages 700--702 in Russell-Norvig (pp. 723--725 in the 3rd ed.) and in the slides and run it on your data set. As suggested program structure, use two functions: \n",
    " * `fit(X, y)` that will return `w` (the model). You can choose a stochastic or batch variant;\n",
    " * `predict(X, w)` that will return `y_hat`. You can encapsulate these functions in a class and, of course, add more parameters.\n",
    "2. As a stop criterion, you will use the number of misclassified examples.\n",
    "3. You will report the parameters you have used and the weight vector\n",
    "\n",
    "You can use numpy or not. The next cells are just suggested steps. You can implement it your way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-singing",
   "metadata": {},
   "source": [
    "### The `predict(X, w)` function\n",
    "Write a `predict(X, w)` function that given a matrix of observations ${X}$ and a weight vector $\\mathbf{w}$ will return a $\\mathbf{\\hat{y}}$ vector classes (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def predict(X, w):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-smoke",
   "metadata": {},
   "source": [
    "### The `fit(X, y)` function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-voice",
   "metadata": {},
   "source": [
    "Write a `fit(X, y)` function that given a matrix of observations ${X}$ and a vector of responses $\\mathbf{y}$ will return a weight $\\mathbf{w}$ vector. You may use the other arguments of the function, notably the number of misclassified examples to define the stop condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "import random\n",
    "\n",
    "\n",
    "def fit_stoch(X, y,\n",
    "              epochs=1000,\n",
    "              max_misclassified=0,\n",
    "              verbose=True):\n",
    "    w = np.zeros(X.shape[1])\n",
    "    ...\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-demand",
   "metadata": {},
   "source": [
    "### Fitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = fit_stoch(X_norm, y)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [w[i] * maxima[-1] / maxima[i] for i in range(len(w))]\n",
    "print(\"Restored weights\", w)\n",
    "w = [w[j] / w[-1] for j in range(len(w))]\n",
    "print(\"Weights with y set to 1\", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-combination",
   "metadata": {},
   "source": [
    "### Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-granny",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_fr, y_fr, color='red')\n",
    "plt.scatter(x_en, y_en, color='blue')\n",
    "plt.plot([min(x_fr + x_en), max(x_fr + x_en)],\n",
    "         [-w[1] * min(x_fr + x_en) - w[0], -w[1] * max(x_fr + x_en) - w[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-liberia",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Evaluate your perceptron using the leave-one-out cross validation method. You will have to train and run 30 models. In each train/run session, you will train on 29 samples and evaluate on the remaining sample. You have then either a correct or a wrong classification. You will sum these classifications, i.e. the number of correct classifications, to get your final evaluation, for instance 29/30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def leave_one_out_cross_val(X, y, fitting_function):\n",
    "    score = 0\n",
    "    ...\n",
    "    return score / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoch_accuracy = leave_one_out_cross_val(X_norm, y, fit_stoch)\n",
    "print('Cross-validation accuracy (stochastic):', stoch_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-saint",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "From your perceptron program, implement logistic regression. You can either follow the description from the slides or from the textbook, S. Russell and R. Norvig, _Artificial Intelligence_, 2022, pages 702--704 (pp. 725--727 in the 3rd ed.). Note that the textbook uses a criterion that is rejected by most practioneers. You can either implement the stochastic or the batch version of the algorithm, or both versions. As stop criterion, you will use either the norm of the gradient or the norm of the difference between two consecutive weight vectors. You will also set a maximal number of epochs. Run the resulting program on your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-affiliation",
   "metadata": {},
   "source": [
    "Write the logistic function, where the $\\mathbf{x}$ input is a vector of real numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def logistic(x):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-violation",
   "metadata": {},
   "source": [
    "### The `predict(X, w)` function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-delaware",
   "metadata": {},
   "source": [
    "Write a `predict_proba()` function that given a matrix of observations ${X}$ and a weight vector $\\mathbf{w}$ will return a vector of probabilities to belong to class 1: The vector will consist of $P(1|\\mathbf{x}_i)$ for all the $i$ rows of ${X}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def predict_proba(X, w):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-equilibrium",
   "metadata": {},
   "source": [
    "Write a `predict(X, w)` function that given a matrix of observations ${X}$ and a weight vector $\\mathbf{w}$ will return the class. You will use `predict_proba()` and set the threshold to belong to class 1 to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def predict(X, w):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-replication",
   "metadata": {},
   "source": [
    "### The `fit(X, y)` function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-bunny",
   "metadata": {},
   "source": [
    "You will now write the `fit(X, y)` function as with the perceptron. You may call it `fit_stoch(X, y)` or `fit_batch(X, y)`. Use the parameters given in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-concentrate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "import random\n",
    "\n",
    "\n",
    "def fit_stoch(X, y, alpha=100,\n",
    "              epochs=1000,\n",
    "              epsilon=1.0e-4,\n",
    "              verbose=False):\n",
    "    w = np.zeros(X.shape[1])\n",
    "    ...\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = fit_stoch(X_norm, y, verbose=True)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [w[i] / maxima[i] for i in range(len(w))]\n",
    "print(\"Restored weights\", w)\n",
    "w = [w[j] / w[-1] for j in range(len(w))]\n",
    "print(\"Weights with y set to 1\", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-correlation",
   "metadata": {},
   "source": [
    "### Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-award",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_fr, y_fr, color='red')\n",
    "plt.scatter(x_en, y_en, color='blue')\n",
    "plt.plot([min(x_fr + x_en), max(x_fr + x_en)],\n",
    "         [-w[1] * min(x_fr + x_en) - w[0], -w[1] * max(x_fr + x_en) - w[0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-database",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Evaluate your logistic regression using the leave-one-out cross validation method as with the perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def leave_one_out_cross_val(X, y, fitting_function):\n",
    "    score = 0\n",
    "    ...\n",
    "    return score / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoch_accuracy = leave_one_out_cross_val(X, y, fit_stoch)\n",
    "print('Cross-validation accuracy (batch):', stoch_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-future",
   "metadata": {},
   "source": [
    "## Visualizing the logistic surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_logistic_surf(x_range, y_range, w_opt):\n",
    "    x_axis, y_axis = np.meshgrid(x_range, y_range)\n",
    "\n",
    "    # We compute the probability surface as a function of x and y\n",
    "    # First generate the (1, x, y) tuples\n",
    "    grid = np.array([[[1.0, i, j] for j in y_range] for i in x_range])\n",
    "    # Then, compute logistic((1, x, y) . w_opt)\n",
    "    z_axis = logistic((grid @ w_opt))\n",
    "    return x_axis, y_axis, z_axis.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-identity",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = np.linspace(0, 100000, 200)\n",
    "y_range = np.linspace(0, 10000, 200)\n",
    "# w = [2.073225839414742, -0.049125455233437906, 0.7440143556104162]\n",
    "\n",
    "x_axis, y_axis, z_axis = plot_logistic_surf(x_range, y_range, w)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig, auto_add_to_figure=False)\n",
    "fig.add_axes(ax)\n",
    "\n",
    "surf = ax.plot_surface(y_axis, x_axis, z_axis, rstride=1, cstride=1, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False, alpha=0.2)\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "# We plot the observations\n",
    "for x, y_class in zip(X, y):\n",
    "    if y_class == 1:\n",
    "        ax.scatter(x[2], x[1], y_class, color='green', marker='x')\n",
    "    else:\n",
    "        ax.scatter(x[2], x[1], y_class, color='red', marker='x')\n",
    "\n",
    "ax.elev = 30\n",
    "ax.azim = -150\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-harassment",
   "metadata": {},
   "source": [
    "## Programming logistic regression with popular APIs\n",
    "Should you use logistic regression in a project, you will probably resort to existing libraries. In the next cells, you will apply the logistic regression classification with two popular APIs:\n",
    "1. sklearn\n",
    "2. Keras\n",
    "\n",
    "`sklearn` is included in anaconda.\n",
    "You will install the rest with:\n",
    "```\n",
    "pip install --upgrade keras-core keras-nightly \n",
    "```\n",
    "You will read and run the code in the three separate notebooks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "promising-spring",
   "metadata": {},
   "source": [
    "## Reading\n",
    "You will read the article *An overview of gradient descent optimization algorithms* by Ruder (2017) and you will outline the main characteristics of all the optimization algorithms the author describes. This part should be of about one to two pages. Link to the article: https://arxiv.org/abs/1609.04747.\n",
    "\n",
    "You can also visualize the descents of the algorithm variants on Ruder's webpage: https://www.ruder.io/optimizing-gradient-descent/.\n",
    "\n",
    "If you understand French, or using Google translate, you may also want to read the original article on gradient descent by Cauchy here:  https://gallica.bnf.fr/ark:/12148/bpt6k2982c/f540.item.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-lodging",
   "metadata": {},
   "source": [
    "### Report\n",
    "\n",
    "The assignment must be documented in the report, which should contain the following:\n",
    "\n",
    "*   The name of the author, the title of the assignment, and any relevant information on the front page;\n",
    "*   A presentation of the assignment and the possible improvements you would have brought;\n",
    "*   A presentation of your implementation;\n",
    "*   A print-out of the example set(s) and the resulting weight vectors;\n",
    "*   Comments on the results you have obtained, including your cross validation;\n",
    "*   A short dissertation on the optimization algorithms from Ruder's paper.\n",
    "\n",
    "Please, typeset and format your report consistently. You must use Latex. Documents written using MS Word or any similar format will not be considered.\n",
    "\n",
    "You may have a look at the code in the textbook code repository (or any other implementations), but the code you hand in must be your work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-blackberry",
   "metadata": {},
   "source": [
    "## Submission\n",
    "Submit the notebook and the report to Canvas (two files). Do not include the code printout in the report, but only comments on its interesting parts. You will submit the notebook as a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-guarantee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
