{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python based viewer tool for \"Probabilistic Reasoning over time\", EDAP01 Artificial Intelligence\n",
    "This notebook has been provided to you by Alexander DÃ¼rr, teaching assistant on the course, spring term 2021. It is based on the ideas and structure of the original Java skeleton for this assignment, provided by Elin A. Topp. Contact us (elin_anna.topp at cs.lth.se) in case you need help!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Installing and activating widgets for Jupyter Notebook\n",
    "To be able to display the visualization (dashboard,animations,etc.) you have to initially install the package  if you don't have it yet"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Use Jupyter Lab for programming, Jupyter Notebook for visualization (optional)\n",
    "This command only enables the extension for jupyter notebook and not in jupyter lab! You can edit from the comfort of jupyter lab though and when you feel like using the widgets just go to\n",
    "\n",
    "Menu bar > Help > Launch Classic Notebook   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we go... inspecting the models, option 1\n",
    "\n",
    "### Your main job will be in the file Filters.py and in the last cell of this notebook, this is only to understand the models\n",
    "\n",
    "In _models_, all the actually interesting stuff is located, and in _Filters_ you should write your own code. Note that the visualization (next cell on inspecting the models, option 2) assumes to have access to an object of type _Localizer_ which in turn expects the filtering / smoothing to happen in _Filters.HMM_Filters.filter(sensorR)_. This means that IF you want to make use of the visualisation in grid-view (below!) also for the actual tracking, you MUST implement the filtering in _Filters.HMM_Filter.filter(sensorR)_ (or make changes in _Localizer.Localizer.update()_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from models import *\n",
    "from view_control.Localizer import Localizer\n",
    "from models.StateModel import StateModel\n",
    "\n",
    "# Testing the models, e.g., for an 4x8 grid\n",
    "\n",
    "states = StateModel( 4, 8)\n",
    "loc = Localizer( states, 1)\n",
    "tMat = loc.get_transition_model()\n",
    "sVecs = loc.get_observation_model()\n",
    "tMat.plot_T()\n",
    "sVecs.plot_o_diags()\n",
    "print(sVecs.get_o_reading(0))\n",
    "print(sVecs.get_o_reading(None))\n",
    "\n",
    "print(loc.update())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we go again... inspecting the models, option 2\n",
    "\n",
    "### Your implementation job will still be in the file Filters.py, this is only to understand the models AND to get a glimpse of a tracking run (but it is slow)\n",
    "\n",
    "In _models_, all the actually interesting stuff is located, and in _Filters_ you should write your own code. Note that this visualization assumes to have access to an object of type Localizer which in turn expects the filtering / smoothing to happen in _Filters.HMM_Filters.filter()_. This means that IF you want to make use of the visualisation in grid-view also for the actual tracking, you MUST implement the filtering in Filters.HMM_Filter.filter() (or make respective changes in _Localizer.Localizer.update()_)\n",
    "\n",
    "### Your Task 1)\n",
    "#### Inspect the visualisation of the models by running the cell and experimenting with the GUI, in particular compare and explain the different versions of the sensor model (see more detailed instructions for the task and report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# In view_control.Dashboard, there is simply the handling of all the thread based visualisation provided, \n",
    "# no changes needed, but feel free...\n",
    "from view_control.Dashboard import Dashboard\n",
    "\n",
    "\n",
    "\n",
    "ROWS = 4\n",
    "COLS = 4\n",
    "\n",
    "# The dashboard creates a state model of the dimensions given by ROWS and COLS, sets up the respective \n",
    "# Transition and Observation models, as well as an instance of class Localizer. The Localizer calls at the \n",
    "# moment a stubb method toDo.Filters.HMMFilter.filter(sensorReading), which just sends back the original \n",
    "# probability distribution - no filtering is done. It is your task to implement something useful there.\n",
    "\n",
    "# Non-uniform failure is the default sensor, sensor 0. Change to 1 if that is your default \n",
    "# (uniform sensor failure)\n",
    "sensorType = 0\n",
    "dash = Dashboard(ROWS, COLS, sensorType)\n",
    "display(dash.db)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write your own \"main\" here (without the viewer)\n",
    "\n",
    "### Your task 2)\n",
    "#### Implement both Forward Filtering and Forward-Backward Smoothing with k = t-5 (a sequence length of 5)\n",
    "#### Do evaluations (500 steps should be enough also for the bigger grids) according to the following, adapt the number of steps or the size of the grid if needed, but comment on it\n",
    "#### Provide plots of the Manhattan distance over time\n",
    "\n",
    "1)\n",
    "* Forward Filtering with non-uniform sensor failure on 8x8 grid against\n",
    "* Sensor output only (non-uniform sensor failure, count sensor failures to get the average frequency, but do not count those steps into the avg Manhattan distance) on 8x8 grid \n",
    "\n",
    "\n",
    "2)\n",
    "* Forward Filtering with non-uniform sensor failure on 4x4 grid against\n",
    "* Forward Filtering with uniform sensor failure on 4x4 grid\n",
    "\n",
    "\n",
    "3)\n",
    "* Forward Filtering with non-uniform sensor failure on 16x20 grid against\n",
    "* Forward Filtering with uniform sensor failure on 16x20 grid\n",
    "\n",
    "\n",
    "4)\n",
    "* Forward Filtering with non-uniform sensor failure on 10x10 grid against\n",
    "* Smoothing (forward-backward smoothing) with k = t-5 (five steps for b) and non-uniform sensor failure on 10x10 grid\n",
    "\n",
    "#### OBS: obviously, each pair-wise evaluation should be run based on the same true trajectory (cases 1, 2, 3) or same trajectory AND same sensor reading sequence (for case 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Trash code, just for testing purposes\n",
    "\n",
    "\n",
    "\n",
    "from attr import s\n",
    "import numpy as np\n",
    "from Filters import HMMFilter\n",
    "from models.StateModel import StateModel\n",
    "from models.TransitionModel import TransitionModel\n",
    "from models.ObservationModel_NUF import ObservationModelNUF\n",
    "from models.ObservationModel_UF import ObservationModelUF\n",
    "from models.RobotSim import RobotSim\n",
    "from view_control.Dashboard import Dashboard\n",
    "from view_control.Localizer import Localizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def ManhattanDistance(x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    Returns the Manhattan Distance between two points\n",
    "    :param x1: x-coordinate of point 1\n",
    "    :param y1: y-coordinate of point 1\n",
    "    :param x2: x-coordinate of point 2\n",
    "    :param y2: y-coordinate of point 2\n",
    "    :return: The Distance\n",
    "    \"\"\"\n",
    "    dx = abs(x2 - x1)\n",
    "    dy = abs(y2 - y1)\n",
    "    distance = dx + dy\n",
    "    return distance\n",
    "\n",
    "\n",
    "def displayGraph(\n",
    "    data1,\n",
    "    nbrCorrect,\n",
    "    data2,\n",
    "    nbrCorrect2,\n",
    "    data1UF,\n",
    "    nbrCorrect1UF,\n",
    "    data2UF,\n",
    "    nbrCorrect2UF,\n",
    "):\n",
    "    average1 = sum(data1) / len(data1)\n",
    "    average2 = sum(data2) / len(data2)\n",
    "    average1UF = sum(data1UF) / len(data1UF)\n",
    "    average2UF = sum(data2UF) / len(data2UF)\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 5))\n",
    "\n",
    "    fig.suptitle(\"Manhattan Distance for NUF above and UF below\")\n",
    "    axs[0][0].plot(data1)\n",
    "    axs[0][0].set_title(\"Filtered Data\")\n",
    "    axs[0][0].set_xlabel(\n",
    "        \" average: \"\n",
    "        + str(average1)\n",
    "        + \" Correct Guesses: \"\n",
    "        + str(round(nbrCorrect / len(data1) * 100, 2))\n",
    "        + \"%\"\n",
    "    )\n",
    "    axs[0][0].set_ylabel(\"Distance\")\n",
    "\n",
    "    axs[1][0].plot(data2)\n",
    "    axs[1][0].set_title(\"Smoothed Data\")\n",
    "    axs[1][0].set_xlabel(\n",
    "        \" average: \"\n",
    "        + str(average2)\n",
    "        + \" Correct Guesses: \"\n",
    "        + str(round(nbrCorrect2 / len(data2) * 100, 2))\n",
    "        + \"%\"\n",
    "    )\n",
    "    axs[1][0].set_ylabel(\"Distance\")\n",
    "\n",
    "    axs[0][1].plot(data1UF)\n",
    "    axs[0][1].set_title(\"Filtered Data UF\")\n",
    "    axs[0][1].set_xlabel(\n",
    "        \" average: \"\n",
    "        + str(average1UF)\n",
    "        + \" Correct Guesses: \"\n",
    "        + str(round(nbrCorrect1UF / len(data1UF) * 100, 2))\n",
    "        + \"%\"\n",
    "    )\n",
    "    axs[0][1].set_ylabel(\"Distance\")\n",
    "\n",
    "    axs[1][1].plot(data2UF)\n",
    "    axs[1][1].set_title(\"Smoothed Data UF\")\n",
    "    axs[1][1].set_xlabel(\n",
    "        \" average: \"\n",
    "        + str(average2UF)\n",
    "        + \" Correct Guesses: \"\n",
    "        + str(round(nbrCorrect2UF / len(data2UF) * 100, 2))\n",
    "        + \"%\"\n",
    "    )\n",
    "    axs[1][1].set_ylabel(\"Distance\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    REPS = 500\n",
    "    ROWS = 10\n",
    "    COLS = 10\n",
    "    nbr_correct1 = 0\n",
    "    nbr_correct2 = 0\n",
    "    nbr_correct1UF = 0\n",
    "    nbr_correct2UF = 0\n",
    "    avg_error1 = 0\n",
    "    avg_error2 = 0\n",
    "    avg_error1UF = 0\n",
    "    avg_error2UF = 0\n",
    "    total_error1 = 0\n",
    "    total_error2 = 0\n",
    "    total_error1UF = 0\n",
    "    total_error2UF = 0\n",
    "    error_array1 = []\n",
    "    error_array2 = []\n",
    "    error_array1UF = []\n",
    "    error_array2UF = []\n",
    "\n",
    "    # Initialize models and filters\n",
    "    state_model = StateModel(ROWS, COLS)\n",
    "    transition_model = TransitionModel(state_model)\n",
    "    NUF = ObservationModelNUF(state_model)\n",
    "    UF = ObservationModelUF(state_model)\n",
    "\n",
    "    nbr_of_states = state_model.get_num_of_states()\n",
    "    probs1 = np.ones(nbr_of_states) / nbr_of_states\n",
    "    probs2 = np.ones(nbr_of_states) / nbr_of_states\n",
    "    probs1UF = np.ones(nbr_of_states) / nbr_of_states\n",
    "    probs2UF = np.ones(nbr_of_states) / nbr_of_states\n",
    "    true_pos = 0\n",
    "    sensor_pos1 = None\n",
    "\n",
    "    HMMF1 = HMMFilter(probs1, transition_model, NUF, state_model)\n",
    "    HMMF2 = HMMFilter(probs2, transition_model, NUF, state_model)\n",
    "    HMMFUF1 = HMMFilter(probs1, transition_model, UF, state_model)\n",
    "    HMMFUF2 = HMMFilter(probs2, transition_model, UF, state_model)\n",
    "\n",
    "    robot_sim = RobotSim(true_pos, state_model)\n",
    "\n",
    "    last_five = []\n",
    "    last_five_UF = []\n",
    "    for _ in range(5):\n",
    "        true_pos_smoothing = robot_sim.move_once(transition_model)\n",
    "        true_pos_smoothing_UF = true_pos_smoothing\n",
    "        sensor_pos1 = robot_sim.sense_in_current_state(NUF)\n",
    "        sensor_pos2 = robot_sim.sense_in_current_state(UF)\n",
    "\n",
    "        last_five.append([true_pos_smoothing, sensor_pos1])\n",
    "        last_five_UF.append([true_pos_smoothing_UF, sensor_pos2])\n",
    "\n",
    "    for m in range(REPS):\n",
    "        true_pos = robot_sim.move_once(transition_model)\n",
    "        sensor_pos1 = robot_sim.sense_in_current_state(NUF)\n",
    "        sensor_pos2 = robot_sim.sense_in_current_state(UF)\n",
    "        probs1 = HMMF1.filter(sensor_pos1)\n",
    "        probs1UF = HMMFUF1.filter(sensor_pos2)\n",
    "\n",
    "        last_five.append([true_pos, sensor_pos1])\n",
    "        last_five_UF.append([true_pos, sensor_pos2])\n",
    "        true_pos_smoothing, sensor_pos1 = last_five[0]\n",
    "        true_pos_smoothing_UF, sensor_pos2 = last_five_UF[0]\n",
    "        last_five = last_five[1:]\n",
    "        last_five_UF = last_five_UF[1:]\n",
    "        probs2 = HMMF2.smoothFilter(last_five, sensor_pos1)\n",
    "        probs2UF = HMMFUF2.smoothFilter(last_five_UF, sensor_pos2)\n",
    "\n",
    "        fPositions1 = probs1.copy()\n",
    "        fPositions2 = probs2.copy()\n",
    "        fPositions1UF = probs1UF.copy()\n",
    "        fPositions2UF = probs2UF.copy()\n",
    "\n",
    "        for state in range(0, state_model.get_num_of_states(), 4):\n",
    "            fPositions1[state : state + 4] = sum(fPositions1[state : state + 4])\n",
    "            fPositions2[state : state + 4] = sum(fPositions2[state : state + 4])\n",
    "            fPositions1UF[state : state + 4] = sum(fPositions1UF[state : state + 4])\n",
    "            fPositions2UF[state : state + 4] = sum(fPositions2UF[state : state + 4])\n",
    "\n",
    "        estimate1 = state_model.state_to_position(int(np.argmax(fPositions1)))\n",
    "        estimate2 = state_model.state_to_position(int(np.argmax(fPositions2)))\n",
    "\n",
    "        estimate1UF = state_model.state_to_position(int(np.argmax(fPositions1UF)))\n",
    "        estimate2UF = state_model.state_to_position(int(np.argmax(fPositions2UF)))\n",
    "\n",
    "        tsX1, tsY1 = state_model.state_to_position(true_pos)\n",
    "        tsX2, tsY2 = state_model.state_to_position(true_pos_smoothing)\n",
    "        eX1, eY1 = estimate1\n",
    "        eX2, eY2 = estimate2\n",
    "\n",
    "        tsX1UF, tsY1UF = state_model.state_to_position(true_pos)\n",
    "        tsX2UF, tsY2UF = state_model.state_to_position(true_pos_smoothing_UF)\n",
    "        eX1UF, eY1UF = estimate1UF\n",
    "        eX2UF, eY2UF = estimate2UF\n",
    "\n",
    "        if eX1 == tsX1 and eY1 == tsY1:\n",
    "            nbr_correct1 += 1\n",
    "\n",
    "        if eX2 == tsX2 and eY2 == tsY2:\n",
    "            nbr_correct2 += 1\n",
    "\n",
    "        if eX1UF == tsX1UF and eY1UF == tsY1UF:\n",
    "            nbr_correct1UF += 1\n",
    "\n",
    "        if eX2UF == tsX2UF and eY2UF == tsY2UF:\n",
    "            nbr_correct2UF += 1\n",
    "\n",
    "        error1 = abs(tsX1 - eX1) + abs(tsY1 - eY1)\n",
    "        error2 = abs(tsX2 - eX2) + abs(tsY2 - eY2)\n",
    "        total_error1 += error1\n",
    "        total_error2 += error2\n",
    "        error_array1.append(error1)\n",
    "        error_array2.append(error2)\n",
    "\n",
    "        error1UF = abs(tsX1UF - eX1UF) + abs(tsY1UF - eY1UF)\n",
    "        error2UF = abs(tsX2UF - eX2UF) + abs(tsY2UF - eY2UF)\n",
    "        total_error1UF += error1UF\n",
    "        total_error2UF += error2UF\n",
    "        error_array1UF.append(error1UF)\n",
    "        error_array2UF.append(error2UF)\n",
    "\n",
    "    avg_error1 = total_error1 / REPS\n",
    "    avg_error2 = total_error2 / REPS\n",
    "\n",
    "    avg_error1UF = total_error1UF / REPS\n",
    "    avg_error2UF = total_error2UF / REPS\n",
    "\n",
    "    print(\"Average Error for Filter 1 UF:\", avg_error1UF)\n",
    "    print(\"Average Error for Filter 2 UF:\", avg_error2UF)\n",
    "    print(\"Number of Correct Estimations for Filter 1 UF:\", nbr_correct1UF)\n",
    "    print(\"Number of Correct Estimations for Filter 2 UF:\", nbr_correct2UF)\n",
    "\n",
    "    print(\"Average Error for Filter 1:\", avg_error1)\n",
    "    print(\"Average Error for Filter 2:\", avg_error2)\n",
    "    print(\"Number of Correct Estimations for Filter 1:\", nbr_correct1)\n",
    "    print(\"Number of Correct Estimations for Filter 2:\", nbr_correct2)\n",
    "\n",
    "    displayGraph(\n",
    "        error_array1,\n",
    "        nbr_correct1,\n",
    "        error_array2,\n",
    "        nbr_correct2,\n",
    "        error_array1UF,\n",
    "        nbr_correct1UF,\n",
    "        error_array2UF,\n",
    "        nbr_correct2UF,\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
